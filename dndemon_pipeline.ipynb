{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ad5460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dndemon_creation\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionXLPipeline, ControlNetModel,StableDiffusionXLImg2ImgPipeline\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os, json, time, gc, shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9d22944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device name: NVIDIA GeForce RTX 4070\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47a668ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset (replace with your path)\n",
    "with open(\"pokemon_dataset_100.json\", \"r\") as f:\n",
    "    pokemon_pairs = json.load(f)[:5]\n",
    "\n",
    "print(type(pokemon_pairs))   # <class 'list'>\n",
    "print(len(pokemon_pairs))    # 100 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46addf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_pairs = [\n",
    "    {\n",
    "        \"base_name\": \"Flamkit\",\n",
    "        \"evolved_name\": \"Pyrolynx\",\n",
    "        \"base\": {\n",
    "            \"prompt\": \"small fiery lynx cub, orange and gold fur with ember tips, glowing paws, anime game art, cel-shaded, cute and energetic, full body, vibrant warm lighting, clean lineart\",\n",
    "            \"negative\": \"text, watermark, signature, extra limbs, bad anatomy, lowres, deformed, human form, armor, humanoid\"\n",
    "        },\n",
    "        \"evolved\": {\n",
    "            \"prompt\": (\n",
    "                \"Evolved warrior version of the creature in the image: bipedal feline warrior \"\n",
    "                \"with two legs and two arms, sleek flaming armor forming from its mane, glowing claws and tail embers, \"\n",
    "                \"retains orange-gold palette and feline facial features, upright battle stance, anime RPG art style, \"\n",
    "                \"cel-shaded, dynamic lighting, clean lineart, coherent humanoid anatomy, high detail\"\n",
    "            ),\n",
    "            \"negative\": (\n",
    "                \"quadruped, four legs, deer, dog, cat on all fours, hooves, animal muzzle, flat lighting, blurry, \"\n",
    "                \"text, watermark, malformed body, low quality, distorted proportions\"\n",
    "            ),\n",
    "            \"strength\": 0.8,\n",
    "            \"guidance_scale\": 7.4\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"base_name\": \"Spriggle\",\n",
    "        \"evolved_name\": \"Verdawn\",\n",
    "        \"base\": {\n",
    "            \"prompt\": \"tiny green reptile sprouting leaves along its spine, big eyes, curious expression, anime cel-shaded, vibrant jungle background, full body\",\n",
    "            \"negative\": \"text, watermark, signature, armor, humanoid, metallic, bad anatomy\"\n",
    "        },\n",
    "        \"evolved\": {\n",
    "            \"prompt\": (\n",
    "                \"Evolved humanoid forest guardian version of the creature in the image: tall bipedal lizard with arms and legs wrapped in vines, \"\n",
    "                \"wooden bark armor forming on shoulders, leafy antler crown, glowing green eyes, retains bright green and earthy brown palette, \"\n",
    "                \"majestic stance, anime fantasy art, cel-shaded, clean lineart, detailed texture work, coherent anatomy\"\n",
    "            ),\n",
    "            \"negative\": (\n",
    "                \"quadruped, small creature, insectoid, blob-like, mechanical, metallic, low quality, flat colors, \"\n",
    "                \"extra limbs, malformed anatomy, text, watermark\"\n",
    "            ),\n",
    "            \"strength\": 0.75,\n",
    "            \"guidance_scale\": 7.2\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"base_name\": \"Aquibbit\",\n",
    "        \"evolved_name\": \"Hydrap\",\n",
    "        \"base\": {\n",
    "            \"prompt\": \"small blue amphibian creature with bubble-like skin, wide smile, tiny fins, anime style, cel-shaded, water reflections, full body\",\n",
    "            \"negative\": \"text, watermark, signature, humanoid, armor, bad anatomy\"\n",
    "        },\n",
    "        \"evolved\": {\n",
    "            \"prompt\": (\n",
    "                \"Evolved sea-serpent version of the creature in the image: long aquatic dragon with three flowing fins on each side, \"\n",
    "                \"bioluminescent markings, glowing underbelly, water swirling around, retains deep blue and cyan palette, \"\n",
    "                \"anime fantasy art, cel-shaded, fluid composition, dynamic lighting, high detail\"\n",
    "            ),\n",
    "            \"negative\": (\n",
    "                \"frog-like, bipedal humanoid, mammal features, extra limbs, mechanical, lowres, blurry, bad perspective, text, watermark\"\n",
    "            ),\n",
    "            \"strength\": 0.7,\n",
    "            \"guidance_scale\": 7.0\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"base_name\": \"Volpup\",\n",
    "        \"evolved_name\": \"Stormane\",\n",
    "        \"base\": {\n",
    "            \"prompt\": \"small electric fox cub, yellow fur with blue lightning streaks, anime cel-shaded, clean lineart, energetic expression, full body\",\n",
    "            \"negative\": \"text, watermark, signature, humanoid, extra limbs, bad anatomy\"\n",
    "        },\n",
    "        \"evolved\": {\n",
    "            \"prompt\": (\n",
    "                \"Evolved humanoid thunder guardian version of the creature in the image: upright fox-like warrior with blue lightning armor, \"\n",
    "                \"spiked tail glowing with electric energy, storm aura around body, retains yellow-blue palette, anime RPG art style, \"\n",
    "                \"cel-shaded, dramatic pose, coherent humanoid anatomy, heroic silhouette, glowing eyes\"\n",
    "            ),\n",
    "            \"negative\": (\n",
    "                \"quadruped fox, four-legged animal, hooves, dog body, flat lighting, messy lineart, lowres, malformed limbs, text, watermark\"\n",
    "            ),\n",
    "            \"strength\": 0.85,\n",
    "            \"guidance_scale\": 7.6\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"base_name\": \"Frystail\",\n",
    "        \"evolved_name\": \"Cryovian\",\n",
    "        \"base\": {\n",
    "            \"prompt\": \"small ice fox creature, white and cyan fur, frosty breath, anime game art, cel-shaded, full body, snowy background, cute expression\",\n",
    "            \"negative\": \"text, watermark, signature, armor, humanoid, fire, bad anatomy\"\n",
    "        },\n",
    "        \"evolved\": {\n",
    "            \"prompt\": (\n",
    "                \"Evolved spirit form of the creature in the image: ethereal bipedal fox spirit with flowing frost robes, \"\n",
    "                \"crystal antlers, glowing cyan eyes, body made of semi-transparent ice shards, retains cyan-white color palette, \"\n",
    "                \"anime fantasy art, high detail, cel-shaded, elegant posture, magical aura\"\n",
    "            ),\n",
    "            \"negative\": (\n",
    "                \"animal fox, quadruped, solid metal, mechanical, distorted anatomy, melted textures, text, watermark, low quality\"\n",
    "            ),\n",
    "            \"strength\": 0.8,\n",
    "            \"guidance_scale\": 7.5\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"base_name\": \"Tuskip\",\n",
    "        \"evolved_name\": \"Ironusk\",\n",
    "        \"base\": {\n",
    "            \"prompt\": \"small gray boar creature with tiny tusks and rough fur, muddy terrain, anime cel-shaded, cute yet tough, full body\",\n",
    "            \"negative\": \"text, watermark, signature, humanoid, armor, deformed, bad anatomy\"\n",
    "        },\n",
    "        \"evolved\": {\n",
    "            \"prompt\": (\n",
    "                \"Evolved armored beast form of the creature in the image: massive iron-plated boar with glowing red tusks, molten cracks along armor, \"\n",
    "                \"steam rising from nostrils, retains gray and brown palette, anime battle art, cel-shaded, dynamic pose, heavy metallic detail\"\n",
    "            ),\n",
    "            \"negative\": (\n",
    "                \"humanoid, bipedal, small piglet, organic flesh armor, distorted limbs, text, watermark, flat lighting\"\n",
    "            ),\n",
    "            \"strength\": 0.6,\n",
    "            \"guidance_scale\": 7.1\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"base_name\": \"Lumini\",\n",
    "        \"evolved_name\": \"Auralis\",\n",
    "        \"base\": {\n",
    "            \"prompt\": \"tiny floating jellyfish-like creature, soft purple glow, translucent body, anime cel-shaded, underwater lighting, gentle expression\",\n",
    "            \"negative\": \"text, watermark, signature, human face, extra limbs, bad anatomy\"\n",
    "        },\n",
    "        \"evolved\": {\n",
    "            \"prompt\": (\n",
    "                \"Evolved celestial being version of the creature in the image: tall humanoid made of glowing jellyfish light, \"\n",
    "                \"flowing tendrils for hair, floating bioluminescent halo, transparent body showing light veins, retains soft purple and pink palette, \"\n",
    "                \"anime ethereal art, celestial glow, clean lineart, high detail\"\n",
    "            ),\n",
    "            \"negative\": (\n",
    "                \"small jellyfish, fish body, quadruped, opaque textures, mechanical, low quality, overexposed, flat background, text, watermark\"\n",
    "            ),\n",
    "            \"strength\": 0.85,\n",
    "            \"guidance_scale\": 7.3\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"base_name\": \"Pebblit\",\n",
    "        \"evolved_name\": \"Georok\",\n",
    "        \"base\": {\n",
    "            \"prompt\": \"tiny rock golem with moss patches, round body, glowing eyes, anime cel-shaded, full body, earthy colors\",\n",
    "            \"negative\": \"text, watermark, signature, humanoid, animal, bad anatomy\"\n",
    "        },\n",
    "        \"evolved\": {\n",
    "            \"prompt\": (\n",
    "                \"Evolved guardian version of the creature in the image: towering humanoid golem made of layered stone and moss armor, \"\n",
    "                \"ancient rune carvings glowing on chest and arms, retains earthy brown and green palette, anime fantasy art, cel-shaded, \"\n",
    "                \"clean lineart, massive presence, coherent humanoid anatomy\"\n",
    "            ),\n",
    "            \"negative\": (\n",
    "                \"tiny golem, quadruped, blob shape, metal body, mechanical, distorted proportions, text, watermark, lowres\"\n",
    "            ),\n",
    "            \"strength\": 0.8,\n",
    "            \"guidance_scale\": 7.4\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"base_name\": \"Glintbug\",\n",
    "        \"evolved_name\": \"Luminid\",\n",
    "        \"base\": {\n",
    "            \"prompt\": \"small insect creature with glowing abdomen, metallic wings, yellow and teal hues, anime cel-shaded, clean lineart, cute design\",\n",
    "            \"negative\": \"text, watermark, signature, humanoid, distorted, bad anatomy\"\n",
    "        },\n",
    "        \"evolved\": {\n",
    "            \"prompt\": (\n",
    "                \"Evolved luminous insect queen version of the creature in the image: massive moth-dragon hybrid with radiant crystalized wings, \"\n",
    "                \"luminescent patterns that pulse with energy, retains yellow and teal palette, elegant posture, glowing aura, \"\n",
    "                \"anime fantasy art, cel-shaded, intricate detail, dynamic lighting\"\n",
    "            ),\n",
    "            \"negative\": (\n",
    "                \"small bug, flat wings, low detail, humanoid, distorted body, asymmetrical, blurred, text, watermark\"\n",
    "            ),\n",
    "            \"strength\": 0.65,\n",
    "            \"guidance_scale\": 7.1\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"base_name\": \"Duskit\",\n",
    "        \"evolved_name\": \"Noctyros\",\n",
    "        \"base\": {\n",
    "            \"prompt\": \"small bat-like creature, dark purple fur, glowing magenta eyes, playful pose, anime cel-shaded, clean lineart\",\n",
    "            \"negative\": \"text, watermark, signature, humanoid, deformed, mechanical\"\n",
    "        },\n",
    "        \"evolved\": {\n",
    "            \"prompt\": (\n",
    "                \"Evolved dark warrior form of the creature in the image: tall humanoid bat knight with cloak-like wings, ornate armor with glowing magenta runes, \"\n",
    "                \"sharp claws and piercing eyes, retains purple-magenta palette, anime RPG art style, dynamic lighting, heroic stance, cel-shaded, high detail\"\n",
    "            ),\n",
    "            \"negative\": (\n",
    "                \"small bat, quadruped, animal-only, deer, malformed face, distorted proportions, text, watermark, lowres, low quality\"\n",
    "            ),\n",
    "            \"strength\": 0.82,\n",
    "            \"guidance_scale\": 7.6\n",
    "        }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "661d8611",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "dtype = torch.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2285c267",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:  43%|████▎     | 3/7 [00:04<00:06,  1.63s/it]`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:06<00:00,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    torch_dtype=dtype,\n",
    "    use_safetensors=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03df4706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevent black outputs on some setups:\n",
    "pipe.enable_attention_slicing()\n",
    "pipe.enable_vae_tiling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a357637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"pokemon_out\"  # ensure defined\n",
    "try:\n",
    "    shutil.rmtree(output_dir)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    pass\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac0d5858",
   "metadata": {},
   "outputs": [],
   "source": [
    "SINGLE_SUBJECT_ADDON = (\n",
    "    \"SINGLE SUBJECT, SOLO, ONE CREATURE ONLY, CENTERED, FULL BODY, \"\n",
    "    \"plain neutral background, subject isolated, studio backdrop\"\n",
    ")\n",
    "\n",
    "SINGLE_SUBJECT_NEG = (\n",
    "    \"multiple creatures, duplicate creature, twins, second creature, extra subject, group, crowd, swarm, \"\n",
    "    \"background characters, reflection duplicates, photobomb, collage, split screen, multi-panel\"\n",
    ")\n",
    "\n",
    "def make_single_subject(prompt: str, negative: str = \"\"):\n",
    "    p = f\"{prompt}, {SINGLE_SUBJECT_ADDON}\"\n",
    "    n = (negative + \", \" if negative else \"\") + SINGLE_SUBJECT_NEG\n",
    "    return p, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b33555b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAKING Flamkit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dndemon_creation\\venv\\Lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:96: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flamkit took 11.33s\n",
      "MAKING Spriggle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:07<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spriggle took 10.24s\n",
      "MAKING Aquibbit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:07<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aquibbit took 10.67s\n",
      "MAKING Volpup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:09<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volpup took 12.55s\n",
      "MAKING Frystail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:06<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frystail took 9.18s\n",
      "MAKING Tuskip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:07<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuskip took 10.70s\n",
      "MAKING Lumini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:06<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lumini took 10.75s\n",
      "MAKING Pebblit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:06<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pebblit took 9.71s\n",
      "MAKING Glintbug\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:06<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glintbug took 9.53s\n",
      "MAKING Duskit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:06<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duskit took 10.59s\n",
      "Total: 105.3s (avg 1.05s/img)\n"
     ]
    }
   ],
   "source": [
    "start_global = time.perf_counter()\n",
    "for pair in pokemon_pairs:\n",
    "    base_name = pair[\"base_name\"]\n",
    "    \n",
    "    base_p, base_n = make_single_subject(pair[\"base\"][\"prompt\"], pair[\"base\"][\"negative\"])\n",
    "    print(f\"MAKING {base_name}\")\n",
    "\n",
    "    out_folder = os.path.join(output_dir, base_name)\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "    base_info = pair[\"base\"]\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    # Optional: ensure no stale work on the device\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    result = pipe(\n",
    "        prompt=base_p,\n",
    "        negative_prompt=base_n + ', text, extra limbs, watermark, multiple bodies, character sheet, concept sheet, turnaround, orthographic, reference sheet, multiple angles, extra head, extra limbs, dismembered parts, split view, multiple views, alternate poses, layout, blueprint, overlay, design board, draft, cutout, outline, diagram, showcase, dissection, duplicated face, extra body',\n",
    "        num_inference_steps=26,\n",
    "        guidance_scale=8.0,\n",
    "        height=832, width=832,\n",
    "    )\n",
    "\n",
    "    img = result.images[0]\n",
    "    img.save(os.path.join(out_folder, f\"{base_name}.png\"))\n",
    "\n",
    "    # ---- cleanup to avoid iteration-to-iteration slowdown ----\n",
    "    del img, result\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()   # free unattached cached blocks\n",
    "        torch.cuda.synchronize()   # finalize GPU work before timing\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    print(f\"{base_name} took {t1 - t0:.2f}s\")\n",
    "\n",
    "end_global = time.perf_counter()\n",
    "print(f\"Total: {end_global - start_global:.1f}s (avg {(end_global - start_global)/100:.2f}s/img)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb81bcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    torch_dtype=dtype,\n",
    "    use_safetensors=True\n",
    ").to(device)\n",
    "\n",
    "\n",
    "pipe.enable_attention_slicing()   # reduces peak VRAM (slightly slower but more stable)\n",
    "pipe.enable_vae_tiling()          # helpful if you go larger than 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d315648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (99 > 77). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['subject, solo, one creature only, centered, full body, plain neutral background, subject isolated, studio backdrop']\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (99 > 77). Running this sequence through the model will result in indexing errors\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['subject, solo, one creature only, centered, full body, plain neutral background, subject isolated, studio backdrop']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAKING Flamkit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:07<00:00,  3.70it/s]\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', one creature only, centered, full body, plain neutral background, subject isolated, studio backdrop']\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', one creature only, centered, full body, plain neutral background, subject isolated, studio backdrop']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flamkit took 8.85s\n",
      "MAKING Spriggle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:04<01:45,  4.21s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     16\u001b[39m init_img = Image.open(os.path.join(out_folder, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.png\u001b[39m\u001b[33m\"\u001b[39m)).convert(\u001b[33m\"\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m evolved_p, evolved_n = make_single_subject(pair[\u001b[33m\"\u001b[39m\u001b[33mevolved\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m], pair[\u001b[33m\"\u001b[39m\u001b[33mevolved\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mnegative\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m result = \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevolved_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevolved_n\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_n\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m, text, extra limbs, watermark, multiple bodies, character sheet, concept sheet, turnaround, orthographic, reference sheet, multiple angles, extra head, extra limbs, dismembered parts, split view, multiple views, alternate poses, layout, blueprint, overlay, design board, draft, cutout, outline, diagram, showcase, dissection, duplicated face, extra body\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_inference_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m26\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstength\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_img\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m832\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m832\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m img = result.images[\u001b[32m0\u001b[39m]\n\u001b[32m     31\u001b[39m img.save(os.path.join(out_folder, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.png\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dndemon_creation\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dndemon_creation\\venv\\Lib\\site-packages\\diffusers\\pipelines\\stable_diffusion_xl\\pipeline_stable_diffusion_xl.py:1217\u001b[39m, in \u001b[36mStableDiffusionXLPipeline.__call__\u001b[39m\u001b[34m(self, prompt, prompt_2, height, width, num_inference_steps, timesteps, sigmas, denoising_end, guidance_scale, negative_prompt, negative_prompt_2, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, pooled_prompt_embeds, negative_pooled_prompt_embeds, ip_adapter_image, ip_adapter_image_embeds, output_type, return_dict, cross_attention_kwargs, guidance_rescale, original_size, crops_coords_top_left, target_size, negative_original_size, negative_crops_coords_top_left, negative_target_size, clip_skip, callback_on_step_end, callback_on_step_end_tensor_inputs, **kwargs)\u001b[39m\n\u001b[32m   1215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ip_adapter_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m ip_adapter_image_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1216\u001b[39m     added_cond_kwargs[\u001b[33m\"\u001b[39m\u001b[33mimage_embeds\u001b[39m\u001b[33m\"\u001b[39m] = image_embeds\n\u001b[32m-> \u001b[39m\u001b[32m1217\u001b[39m noise_pred = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43munet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlatent_model_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimestep_cond\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimestep_cond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43madded_cond_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43madded_cond_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m   1227\u001b[39m \u001b[38;5;66;03m# perform guidance\u001b[39;00m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.do_classifier_free_guidance:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dndemon_creation\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dndemon_creation\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dndemon_creation\\venv\\Lib\\site-packages\\diffusers\\models\\unets\\unet_2d_condition.py:1215\u001b[39m, in \u001b[36mUNet2DConditionModel.forward\u001b[39m\u001b[34m(self, sample, timestep, encoder_hidden_states, class_labels, timestep_cond, attention_mask, cross_attention_kwargs, added_cond_kwargs, down_block_additional_residuals, mid_block_additional_residual, down_intrablock_additional_residuals, encoder_attention_mask, return_dict)\u001b[39m\n\u001b[32m   1212\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_adapter \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(down_intrablock_additional_residuals) > \u001b[32m0\u001b[39m:\n\u001b[32m   1213\u001b[39m         additional_residuals[\u001b[33m\"\u001b[39m\u001b[33madditional_residuals\u001b[39m\u001b[33m\"\u001b[39m] = down_intrablock_additional_residuals.pop(\u001b[32m0\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1215\u001b[39m     sample, res_samples = \u001b[43mdownsample_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemb\u001b[49m\u001b[43m=\u001b[49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43madditional_residuals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     sample, res_samples = downsample_block(hidden_states=sample, temb=emb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dndemon_creation\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dndemon_creation\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dndemon_creation\\venv\\Lib\\site-packages\\diffusers\\models\\unets\\unet_2d_blocks.py:1270\u001b[39m, in \u001b[36mCrossAttnDownBlock2D.forward\u001b[39m\u001b[34m(self, hidden_states, temb, encoder_hidden_states, attention_mask, cross_attention_kwargs, encoder_attention_mask, additional_residuals)\u001b[39m\n\u001b[32m   1268\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1269\u001b[39m     hidden_states = resnet(hidden_states, temb)\n\u001b[32m-> \u001b[39m\u001b[32m1270\u001b[39m     hidden_states = \u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1271\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1272\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1273\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1274\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1275\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1276\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1277\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m   1279\u001b[39m \u001b[38;5;66;03m# apply additional residuals to the output of the last pair of resnet and attention blocks\u001b[39;00m\n\u001b[32m   1280\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[38;5;28mlen\u001b[39m(blocks) - \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m additional_residuals \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dndemon_creation\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dndemon_creation\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dndemon_creation\\venv\\Lib\\site-packages\\diffusers\\models\\transformers\\transformer_2d.py:427\u001b[39m, in \u001b[36mTransformer2DModel.forward\u001b[39m\u001b[34m(self, hidden_states, encoder_hidden_states, timestep, added_cond_kwargs, class_labels, cross_attention_kwargs, attention_mask, encoder_attention_mask, return_dict)\u001b[39m\n\u001b[32m    416\u001b[39m         hidden_states = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    417\u001b[39m             block,\n\u001b[32m    418\u001b[39m             hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    424\u001b[39m             class_labels,\n\u001b[32m    425\u001b[39m         )\n\u001b[32m    426\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m         hidden_states = \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimestep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimestep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m            \u001b[49m\u001b[43mclass_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[38;5;66;03m# 3. Output\u001b[39;00m\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_input_continuous:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dndemon_creation\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dndemon_creation\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dndemon_creation\\venv\\Lib\\site-packages\\diffusers\\models\\attention.py:995\u001b[39m, in \u001b[36mBasicTransformerBlock.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, timestep, cross_attention_kwargs, class_labels, added_cond_kwargs)\u001b[39m\n\u001b[32m    992\u001b[39m cross_attention_kwargs = cross_attention_kwargs.copy() \u001b[38;5;28;01mif\u001b[39;00m cross_attention_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    993\u001b[39m gligen_kwargs = cross_attention_kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mgligen\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m995\u001b[39m attn_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattn1\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnorm_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43monly_cross_attention\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.norm_type == \u001b[33m\"\u001b[39m\u001b[33mada_norm_zero\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1003\u001b[39m     attn_output = gate_msa.unsqueeze(\u001b[32m1\u001b[39m) * attn_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dndemon_creation\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dndemon_creation\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dndemon_creation\\venv\\Lib\\site-packages\\diffusers\\models\\attention_processor.py:605\u001b[39m, in \u001b[36mAttention.forward\u001b[39m\u001b[34m(self, hidden_states, encoder_hidden_states, attention_mask, **cross_attention_kwargs)\u001b[39m\n\u001b[32m    600\u001b[39m     logger.warning(\n\u001b[32m    601\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcross_attention_kwargs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munused_kwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m are not expected by \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.processor.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and will be ignored.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    602\u001b[39m     )\n\u001b[32m    603\u001b[39m cross_attention_kwargs = {k: w \u001b[38;5;28;01mfor\u001b[39;00m k, w \u001b[38;5;129;01min\u001b[39;00m cross_attention_kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m attn_parameters}\n\u001b[32m--> \u001b[39m\u001b[32m605\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    608\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    609\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    610\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    611\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "start_global = time.perf_counter()\n",
    "for pair in pokemon_pairs:\n",
    "    base_name = pair[\"base_name\"]\n",
    "    evolved_name = pair[\"evolved_name\"]\n",
    "    print(f\"MAKING {base_name}\")\n",
    "\n",
    "    \n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    # Optional: ensure no stale work on the device\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "   \n",
    "    out_folder = os.path.join(output_dir, base_name)\n",
    "    init_img = Image.open(os.path.join(out_folder, f\"{base_name}.png\")).convert(\"RGB\")\n",
    "    evolved_p, evolved_n = make_single_subject(pair[\"evolved\"][\"prompt\"], pair[\"evolved\"][\"negative\"])\n",
    "\n",
    "    \n",
    "    result = pipe(\n",
    "        prompt=evolved_p,\n",
    "        evolved_n=base_n + ', text, extra limbs, watermark, multiple bodies, character sheet, concept sheet, turnaround, orthographic, reference sheet, multiple angles, extra head, extra limbs, dismembered parts, split view, multiple views, alternate poses, layout, blueprint, overlay, design board, draft, cutout, outline, diagram, showcase, dissection, duplicated face, extra body',\n",
    "        num_inference_steps=26,\n",
    "        stength = 0.9,\n",
    "        image=init_img,\n",
    "        guidance_scale=8.0,\n",
    "        height=832, width=832,\n",
    "    )\n",
    "\n",
    "    img = result.images[0]\n",
    "    img.save(os.path.join(out_folder, f\"{evolved_name}.png\"))\n",
    "\n",
    "    # ---- cleanup to avoid iteration-to-iteration slowdown ----\n",
    "    del img, result\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()   # free unattached cached blocks\n",
    "        torch.cuda.synchronize()   # finalize GPU work before timing\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    print(f\"{evolved_name} took {t1 - t0:.2f}s\")\n",
    "\n",
    "end_global = time.perf_counter()\n",
    "print(f\"Total: {end_global - start_global:.1f}s (avg {(end_global - start_global)/100:.2f}s/img)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a9e4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
